{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flexible-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,re\n",
    "import multiprocessing \n",
    "import h5py\n",
    "import csv\n",
    "import ujson\n",
    "from pyensembl import EnsemblRelease\n",
    "from pyensembl import Genome\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "\n",
    "from m6anet.scripts import helper\n",
    "from m6anet.utils import misc\n",
    "\n",
    "\n",
    "def index(eventalign_result,pos_start,out_paths,locks):\n",
    "    eventalign_result = eventalign_result.set_index(['contig','read_index'])\n",
    "    pos_end=pos_start\n",
    "    with locks['index'], open(out_paths['index'],'a') as f_index:\n",
    "        for index in list(dict.fromkeys(eventalign_result.index)):\n",
    "            transcript_id,read_index = index\n",
    "            pos_end += eventalign_result.loc[index]['line_length'].sum()\n",
    "            f_index.write('%s,%d,%d,%d\\n' %(transcript_id,read_index,pos_start,pos_end))\n",
    "            pos_start = pos_end\n",
    "\n",
    "def parallel_index(eventalign_filepath,summary_filepath,chunk_size,out_dir,n_processes,resume):\n",
    "    # Create output paths and locks.\n",
    "    out_paths,locks = dict(),dict()\n",
    "    for out_filetype in ['index']:\n",
    "        out_paths[out_filetype] = os.path.join(out_dir,'eventalign.%s' %out_filetype)\n",
    "        locks[out_filetype] = multiprocessing.Lock()\n",
    "        \n",
    "        \n",
    "    read_names_done = []\n",
    "    if resume and os.path.exists(out_paths['log']):\n",
    "        read_names_done = [line.rstrip('\\n') for line in open(out_paths['log'],'r')]\n",
    "    else:\n",
    "        # Create empty files.\n",
    "        with open(out_paths['index'],'w') as f:\n",
    "            f.write('transcript_id,read_index,pos_start,pos_end\\n') # header\n",
    "\n",
    "\n",
    "    # Create communication queues.\n",
    "    task_queue = multiprocessing.JoinableQueue(maxsize=n_processes * 2)\n",
    "\n",
    "    # Create and start consumers.\n",
    "    consumers = [helper.Consumer(task_queue=task_queue,task_function=index,locks=locks) for i in range(n_processes)]\n",
    "    for p in consumers:\n",
    "        p.start()\n",
    "        \n",
    "    ## Load tasks into task_queue. A task is eventalign information of one read.\n",
    "    eventalign_file = open(eventalign_filepath,'r')\n",
    "    pos_start = len(eventalign_file.readline()) #remove header\n",
    "    chunk_split = None\n",
    "    index_features = ['contig','read_index','line_length']\n",
    "    i = 0\n",
    "    for chunk in pd.read_csv(eventalign_filepath, chunksize=chunk_size,sep='\\t'):\n",
    "        print(\"processing {}-th chunk\".format(i))\n",
    "        chunk_complete = chunk[chunk['read_index'] != chunk.iloc[-1]['read_index']]\n",
    "        chunk_concat = pd.concat([chunk_split,chunk_complete])\n",
    "        chunk_concat_size = len(chunk_concat.index)\n",
    "        print(chunk_concat_size)\n",
    "        ## read the file at where it left off because the file is opened once ##\n",
    "        lines = [len(eventalign_file.readline()) for i in range(chunk_concat_size)]\n",
    "        chunk_concat['line_length'] = np.array(lines)\n",
    "        print(chunk_concat)\n",
    "        task_queue.put((chunk_concat[index_features],pos_start,out_paths))\n",
    "        pos_start += sum(lines)\n",
    "        chunk_split = chunk[chunk['read_index'] == chunk.iloc[-1]['read_index']]\n",
    "        i += 1\n",
    "    ## the loop above leaves off w/o adding the last read_index to eventalign.index\n",
    "    chunk_split_size = len(chunk_split.index)\n",
    "    lines = [len(eventalign_file.readline()) for i in range(chunk_split_size)]\n",
    "    chunk_split['line_length'] = np.array(lines)\n",
    "    task_queue.put((chunk_split[index_features],pos_start,out_paths))\n",
    "\n",
    "    # Put the stop task into task_queue.\n",
    "    task_queue = helper.end_queue(task_queue,n_processes)\n",
    "\n",
    "    # Wait for all of the tasks to finish.\n",
    "    task_queue.join()\n",
    "\n",
    "def combine(events_str):\n",
    "    f_string = StringIO(events_str)\n",
    "    eventalign_result = pd.read_csv(f_string,delimiter='\\t',names=['contig','position','reference_kmer','read_index',\n",
    "                         'event_level_mean','event_stdv','event_length','model_kmer','start_idx', 'end_idx'])\n",
    "    f_string.close()\n",
    "    cond_successfully_eventaligned = eventalign_result['reference_kmer'] == eventalign_result['model_kmer']\n",
    "    if cond_successfully_eventaligned.sum() != 0:\n",
    "\n",
    "        eventalign_result = eventalign_result[cond_successfully_eventaligned]\n",
    "\n",
    "        keys = ['read_index','contig','position','reference_kmer'] # for groupby\n",
    "        eventalign_result['length'] = pd.to_numeric(eventalign_result['end_idx'])-pd.to_numeric(eventalign_result['start_idx'])\n",
    "        eventalign_result['sum_norm_mean'] = pd.to_numeric(eventalign_result['event_level_mean']) * eventalign_result['length']\n",
    "        eventalign_result['sum_norm_std'] = pd.to_numeric(eventalign_result['event_stdv']) * eventalign_result['length']\n",
    "        eventalign_result['sum_dwell_time'] = pd.to_numeric(eventalign_result['event_length']) * eventalign_result['length']\n",
    "            \n",
    "        eventalign_result = eventalign_result.groupby(keys)  \n",
    "        sum_norm_mean = eventalign_result['sum_norm_mean'].sum() \n",
    "        sum_norm_std = eventalign_result[\"sum_norm_std\"].sum()\n",
    "        sum_dwell_time = eventalign_result[\"sum_dwell_time\"].sum()\n",
    "\n",
    "        start_idx = eventalign_result['start_idx'].min()\n",
    "        end_idx = eventalign_result['end_idx'].max()\n",
    "        total_length = eventalign_result['length'].sum()\n",
    "\n",
    "        eventalign_result = pd.concat([start_idx,end_idx],axis=1)\n",
    "        eventalign_result['norm_mean'] = (sum_norm_mean/total_length).round(1)\n",
    "        eventalign_result[\"norm_std\"] = sum_norm_std / total_length\n",
    "        eventalign_result[\"dwell_time\"] = sum_dwell_time / total_length\n",
    "        eventalign_result.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "        eventalign_result['transcript_id'] = [contig.split('.')[0] for contig in eventalign_result['contig']]    #### CHANGE MADE ####\n",
    "        #eventalign_result['transcript_id'] = eventalign_result['contig']\n",
    "\n",
    "        eventalign_result['transcriptomic_position'] = pd.to_numeric(eventalign_result['position']) + 2 # the middle position of 5-mers.\n",
    "        # eventalign_result = misc.str_encode(eventalign_result)\n",
    "#         eventalign_result['read_id'] = [read_name]*len(eventalign_result)\n",
    "\n",
    "        # features = ['read_id','transcript_id','transcriptomic_position','reference_kmer','norm_mean','start_idx','end_idx']\n",
    "        # features_dtype = np.dtype([('read_id', 'S36'), ('transcript_id', 'S15'), ('transcriptomic_position', '<i8'), ('reference_kmer', 'S5'), ('norm_mean', '<f8'), ('start_idx', '<i8'), ('end_idx', '<i8')])\n",
    "        \n",
    "#         features = ['transcript_id','transcriptomic_position','reference_kmer','norm_mean']\n",
    "\n",
    "#         df_events = eventalign_result[['read_index']+features]\n",
    "#         # print(df_events.head())\n",
    "\n",
    "        features = ['transcript_id','read_index','transcriptomic_position','reference_kmer','norm_mean','norm_std','dwell_time']\n",
    "#        np_events = eventalign_result[features].reset_index().values.ravel().view(dtype=[('transcript_id', 'S15'), ('transcriptomic_position', '<i8'), ('reference_kmer', 'S5'), ('norm_mean', '<f8')])\n",
    "        df_events = eventalign_result[features]\n",
    "        np_events = np.rec.fromrecords(df_events, names=[*df_events])\n",
    "        return np_events\n",
    "\n",
    "def parallel_preprocess_tx(eventalign_filepath,out_dir,n_processes,readcount_min,readcount_max,resume):\n",
    "    \n",
    "    # Create output paths and locks.\n",
    "    out_paths,locks = dict(),dict()\n",
    "    for out_filetype in ['json','index','log','readcount']:\n",
    "        out_paths[out_filetype] = os.path.join(out_dir,'data.%s' %out_filetype)\n",
    "        locks[out_filetype] = multiprocessing.Lock()\n",
    "                \n",
    "    # Writing the starting of the files.\n",
    "    gene_ids_done = []\n",
    "    if resume and os.path.exists(out_paths['index']):\n",
    "        df_index = pd.read_csv(out_paths['index'],sep=',')\n",
    "        gene_ids_done = list(df_index['idx'].unique())\n",
    "    else:\n",
    "        # with open(out_paths['json'],'w') as f:\n",
    "        #     f.write('{\\n')\n",
    "        #     f.write('\"genes\":{')\n",
    "        open(out_paths['json'],'w').close()\n",
    "        with open(out_paths['index'],'w') as f:\n",
    "            f.write('idx,start,end\\n') # header\n",
    "        with open(out_paths['readcount'],'w') as f:\n",
    "            f.write('idx,n_reads\\n') # header\n",
    "        open(out_paths['log'],'w').close()\n",
    "\n",
    "    # Create communication queues.\n",
    "    task_queue = multiprocessing.JoinableQueue(maxsize=n_processes * 2)\n",
    "\n",
    "    # Create and start consumers.\n",
    "    consumers = [helper.Consumer(task_queue=task_queue,task_function=preprocess_tx,locks=locks) for i in range(n_processes)]\n",
    "    for p in consumers:\n",
    "        p.start()\n",
    "    \n",
    "    df_eventalign_index = pd.read_csv(os.path.join(out_dir,'eventalign.index'))\n",
    "    df_eventalign_index['transcript_id'] = [tx_id.split('.')[0] for tx_id in  df_eventalign_index['transcript_id']]\n",
    "    tx_ids = df_eventalign_index['transcript_id'].values.tolist()\n",
    "    tx_ids = list(dict.fromkeys(tx_ids))\n",
    "    df_eventalign_index.set_index('transcript_id',inplace=True)\n",
    "    with open(eventalign_filepath,'r') as eventalign_result:\n",
    "        for tx_id in tx_ids:\n",
    "            data_dict = dict()\n",
    "            readcount = 0\n",
    "            for _,row in df_eventalign_index.loc[[tx_id]].iterrows():\n",
    "                read_index,pos_start,pos_end = row['read_index'],row['pos_start'],row['pos_end']\n",
    "                eventalign_result.seek(pos_start,0)\n",
    "                events_str = eventalign_result.read(pos_end-pos_start)\n",
    "                data = combine(events_str)\n",
    "                if data.size > 1:\n",
    "                    data_dict[read_index] = data\n",
    "                readcount += 1 \n",
    "                if readcount > readcount_max:\n",
    "                    break\n",
    "            if readcount>=readcount_min:\n",
    "                task_queue.put((tx_id,data_dict,out_paths)) # Blocked if necessary until a free slot is available. \n",
    "\n",
    "\n",
    "    # Put the stop task into task_queue.\n",
    "    task_queue = helper.end_queue(task_queue,n_processes)\n",
    "\n",
    "    # Wait for all of the tasks to finish.\n",
    "    task_queue.join()\n",
    "    \n",
    "##    with open(out_paths['log'],'a+') as f:\n",
    "##        f.write('Total %d genes.\\n' %len(gene_ids_processed))\n",
    "##        f.write(helper.decor_message('successfully finished'))\n",
    "\n",
    "def preprocess_tx(tx_id,data_dict,out_paths,locks):  # todo\n",
    "    \"\"\"\n",
    "    Convert transcriptomic to genomic coordinates for a gene.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        tx_id: str\n",
    "            Transcript ID.\n",
    "        data_dict: {read_id:events_array}\n",
    "            Events for each read.\n",
    "        features: [str] # todo\n",
    "            A list of features to collect from the reads that are aligned to each genomic coordinate in the output.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dict of all specified features collected for each genomic coordinate.\n",
    "    \"\"\"\n",
    "    \n",
    "    # features = ['read_id','transcript_id','transcriptomic_position','reference_kmer','norm_mean','start_idx','end_idx'] # columns in the eventalign file per read.\n",
    "\n",
    "    events = []\n",
    "    condition_labels = []\n",
    "    run_labels = []\n",
    "    read_ids = []\n",
    "    transcriptomic_coordinates = []\n",
    "    \n",
    "    # Concatenate\n",
    "    if len(data_dict) == 0:\n",
    "        return\n",
    "\n",
    "    for read_id,events_per_read in data_dict.items(): \n",
    "        # print(read_id)\n",
    "        events += [events_per_read]\n",
    "        \n",
    "    events = np.concatenate(events)\n",
    "   \n",
    "    # Sort and split \n",
    "    idx_sorted = np.lexsort((events['reference_kmer'],events['transcriptomic_position'],events['transcript_id']))\n",
    "    key_tuples, index = np.unique(list(zip(events['transcript_id'][idx_sorted],events['transcriptomic_position'][idx_sorted],events['reference_kmer'][idx_sorted])),return_index = True,axis=0) #'chr',\n",
    "    x_arrays = np.split(events['norm_std'][idx_sorted], index[1:])\n",
    "    y_arrays = np.split(events['norm_mean'][idx_sorted], index[1:])\n",
    "    z_arrays = np.split(events['dwell_time'][idx_sorted], index[1:])\n",
    "    read_id_arrays = np.split(events['read_index'][idx_sorted], index[1:]) ####\n",
    "    reference_kmer_arrays = np.split(events['reference_kmer'][idx_sorted], index[1:])\n",
    "\n",
    "    # Prepare\n",
    "    # print('Reformating the data for each genomic position ...')\n",
    "    data = defaultdict(dict)\n",
    "    # for each position, make it ready for json dump\n",
    "    for key_tuple,x_array,y_array,z_array,read_id_array,reference_kmer_array in zip(key_tuples,x_arrays,y_arrays,z_arrays,read_id_arrays,reference_kmer_arrays):\n",
    "        idx,position,kmer = key_tuple\n",
    "        position = int(position)\n",
    "        kmer = kmer\n",
    "        if (len(set(reference_kmer_array)) == 1) and ('XXXXX' in set(reference_kmer_array)) or (len(y_array) == 0):\n",
    "            continue\n",
    "        ####Hi Chris,\n",
    "        #####Can you figure out how to output a tuple with mean (y_array),sd(x_array),and dwell time(z_array), please?\n",
    "        data[position] = {kmer: list(np.around(y_array,decimals=2))}\n",
    "\n",
    "    # write to file.\n",
    "    log_str = '%s: Data preparation ... Done.' %(tx_id)\n",
    "    with locks['json'], open(out_paths['json'],'a') as f:\n",
    "        pos_start = f.tell()\n",
    "        f.write('{')\n",
    "        f.write('\"%s\":' %tx_id)\n",
    "        ujson.dump(data, f)\n",
    "        f.write('}\\n')\n",
    "        pos_end = f.tell()\n",
    "        \n",
    "    with locks['index'], open(out_paths['index'],'a') as f:\n",
    "        f.write('%s,%d,%d\\n' %(tx_id,pos_start,pos_end))\n",
    "        \n",
    "    with locks['readcount'], open(out_paths['readcount'],'a') as f: #todo: repeats no. of tx >> don't want      n_reads = len(data_dict)\n",
    "        f.write('%s,%d\\n' %(tx_id,n_reads))\n",
    "        \n",
    "    with locks['log'], open(out_paths['log'],'a') as f:\n",
    "        f.write(log_str + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "announced-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventalign_filepath = \"/Users/christopherhendra/m6anet/demo_data/eventalign.txt\"\n",
    "summary_filepath = \"/Users/christopherhendra/m6anet/demo_data/summary.txt\"\n",
    "chunk_size = 1000\n",
    "out_dir = \"/Users/christopherhendra/m6anet/tmp\"\n",
    "n_processes = 4\n",
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arctic-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0-th chunk\n",
      "0\n",
      "Empty DataFrame\n",
      "Columns: [contig, position, reference_kmer, read_index, event_level_mean, event_stdv, event_length, model_kmer, start_idx, end_idx, line_length]\n",
      "Index: []\n",
      "processing 1-th chunk\n",
      "1284\n",
      "                 contig  position reference_kmer  read_index  \\\n",
      "0     ENST00000351111.6      1066          TAGGG           0   \n",
      "1     ENST00000351111.6       280          ACAAC           0   \n",
      "2     ENST00000351111.6       106          CCCGC           0   \n",
      "3     ENST00000351111.6       344          ACACC           0   \n",
      "4     ENST00000351111.6         7          TGGCT           0   \n",
      "...                 ...       ...            ...         ...   \n",
      "1279  ENST00000351111.6       577          TTATC           0   \n",
      "1280  ENST00000351111.6       934          GGCCA           0   \n",
      "1281  ENST00000351111.6       433          TGCTG           0   \n",
      "1282  ENST00000351111.6       395          CCTGA           0   \n",
      "1283  ENST00000351111.6       940          TTGGA           0   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "0                84.11       5.534       0.00498      TAGGG      40500   \n",
      "1                81.64       1.272       0.00564      ACAAC      77029   \n",
      "2                77.50       1.158       0.00299      CCCGC      84574   \n",
      "3                68.51       1.203       0.00365      ACACC      74054   \n",
      "4               112.19       6.697       0.00664      TGGCT      92373   \n",
      "...                ...         ...           ...        ...        ...   \n",
      "1279             88.60       3.201       0.01693      TTATC      62760   \n",
      "1280            102.80       7.854       0.00465      GGCCA      46606   \n",
      "1281            102.55       4.308       0.00299      TGCTG      70479   \n",
      "1282             94.79       2.652       0.00631      CCTGA      72344   \n",
      "1283            106.09       2.820       0.01926      TTGGA      46376   \n",
      "\n",
      "      end_idx  line_length  \n",
      "0       40515           69  \n",
      "1       77046           68  \n",
      "2       84583           67  \n",
      "3       74065           68  \n",
      "4       92393           80  \n",
      "...       ...          ...  \n",
      "1279    62811           67  \n",
      "1280    46620           68  \n",
      "1281    70488           69  \n",
      "1282    72363           95  \n",
      "1283    46434           68  \n",
      "\n",
      "[1284 rows x 11 columns]\n",
      "processing 2-th chunk\n",
      "1214\n",
      "                 contig  position reference_kmer  read_index  \\\n",
      "1284  ENST00000351111.6      1174          GTTGT           1   \n",
      "1285  ENST00000351111.6      1164          CAACC           1   \n",
      "1286  ENST00000351111.6       465          CTGGT           1   \n",
      "1287  ENST00000351111.6      1418          ACCCA           1   \n",
      "1288  ENST00000351111.6       951          GAGGA           1   \n",
      "...                 ...       ...            ...         ...   \n",
      "2493  ENST00000351111.6       441          CTTTT           1   \n",
      "2494  ENST00000351111.6      1071          CTATT           1   \n",
      "2495  ENST00000351111.6       211          CCAGC           1   \n",
      "2496  ENST00000351111.6      1383          CCTGA           1   \n",
      "2497  ENST00000351111.6      1445          CAGGT           1   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "1284             84.92       3.210       0.00299      GTTGT      27455   \n",
      "1285             88.20       1.278       0.00730      CAACC      27703   \n",
      "1286            105.96       2.727       0.00398      CTGGT      57248   \n",
      "1287             64.19       0.730       0.00299      ACCCA      18061   \n",
      "1288            116.68       7.156       0.00332      GAGGA      36368   \n",
      "...                ...         ...           ...        ...        ...   \n",
      "2493             78.98       0.685       0.00365      CTTTT      57939   \n",
      "2494             93.93       2.427       0.01394      CTATT      31700   \n",
      "2495            104.99       5.427       0.00498      CCAGC      66891   \n",
      "2496             86.48       1.775       0.00232      CCTGA      19231   \n",
      "2497            103.68       3.783       0.00764      CAGGT      16579   \n",
      "\n",
      "      end_idx  line_length  \n",
      "1284    27464           68  \n",
      "1285    27725           67  \n",
      "1286    57260           69  \n",
      "1287    18070           68  \n",
      "1288    36378           95  \n",
      "...       ...          ...  \n",
      "2493    57950           68  \n",
      "2494    31742           82  \n",
      "2495    66906           82  \n",
      "2496    19238           69  \n",
      "2497    16602           83  \n",
      "\n",
      "[1214 rows x 11 columns]\n",
      "processing 3-th chunk\n",
      "1499\n",
      "                 contig  position reference_kmer  read_index  \\\n",
      "2498  ENST00000351111.6      1223          GTGCT           2   \n",
      "2499  ENST00000351111.6      1223          GTGCT           2   \n",
      "2500  ENST00000351111.6       691          TGACC           2   \n",
      "2501  ENST00000351111.6       671          CCAGC           2   \n",
      "2502  ENST00000351111.6       501          CGGAT           2   \n",
      "...                 ...       ...            ...         ...   \n",
      "3992  ENST00000351111.6       287          AATGA           2   \n",
      "3993  ENST00000351111.6      1512          TTATA           2   \n",
      "3994  ENST00000351111.6      1459          TGTTA           2   \n",
      "3995  ENST00000351111.6       540          GGCTG           2   \n",
      "3996  ENST00000351111.6       610          TGGTG           2   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "2498             96.20       2.180       0.00332      GTGCT      27516   \n",
      "2499             89.73       1.765       0.00166      GTGCT      27461   \n",
      "2500            116.60       6.965       0.00465      TGACC      55798   \n",
      "2501             93.31       2.396       0.00432      CCAGC      56608   \n",
      "2502            120.67       6.527       0.00266      CGGAT      66184   \n",
      "...                ...         ...           ...        ...        ...   \n",
      "3992             85.72       4.533       0.00631      AATGA      75350   \n",
      "3993             92.63       2.010       0.00564      TTATA      13409   \n",
      "3994            112.07       4.145       0.00332      TGTTA      16298   \n",
      "3995            105.65       3.234       0.01428      GGCTG      64472   \n",
      "3996            119.48       2.778       0.00232      TGGTG      60009   \n",
      "\n",
      "      end_idx  line_length  \n",
      "2498    27526           81  \n",
      "2499    27466           83  \n",
      "2500    55812           68  \n",
      "2501    56621           68  \n",
      "2502    66192           69  \n",
      "...       ...          ...  \n",
      "3992    75369           82  \n",
      "3993    13426           68  \n",
      "3994    16308           84  \n",
      "3995    64515           82  \n",
      "3996    60016           69  \n",
      "\n",
      "[1499 rows x 11 columns]\n",
      "processing 4-th chunk\n",
      "3\n",
      "                 contig  position reference_kmer  read_index  \\\n",
      "3997  ENST00000351111.6        73          TCCAG           3   \n",
      "3998  ENST00000351111.6       336          CTTAT           3   \n",
      "3999  ENST00000351111.6       576          TTTAT           3   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "3997             73.44       0.937       0.00232      TCCAG      88174   \n",
      "3998             83.21       1.629       0.00332      CTTAT      74277   \n",
      "3999             82.78       1.024       0.00564      TTTAT      62060   \n",
      "\n",
      "      end_idx  line_length  \n",
      "3997    88181           67  \n",
      "3998    74287           82  \n",
      "3999    62077           68  \n",
      "processing 5-th chunk\n",
      "1511\n",
      "                 contig  position reference_kmer  read_index  \\\n",
      "4000  ENST00000351111.6      1368          CTCTG           3   \n",
      "4001  ENST00000351111.6        73          TCCAG           3   \n",
      "4002  ENST00000351111.6        15          GCCGT           3   \n",
      "4003  ENST00000351111.6        15          GCCGT           3   \n",
      "4004  ENST00000351111.6        14          GGCCG           3   \n",
      "...                 ...       ...            ...         ...   \n",
      "5506  ENST00000351111.6      1013          ATAGG           3   \n",
      "5507  ENST00000351111.6      1012          GATAG           3   \n",
      "5508  ENST00000351111.6      1384          CTGAA           3   \n",
      "5509  ENST00000351111.6        85          GCTAT           3   \n",
      "5510  ENST00000351111.6      1140          CAACC           3   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "4000             76.38       2.125       0.00730      CTCTG      21422   \n",
      "4001             70.85       1.387       0.00266      TCCAG      88147   \n",
      "4002             75.41       1.973       0.00930      GCCGT      93145   \n",
      "4003             75.78       2.454       0.00299      GCCGT      93320   \n",
      "4004            106.88       4.322       0.02092      GGCCG      93375   \n",
      "...                ...         ...           ...        ...        ...   \n",
      "5506             80.67       3.998       0.00232      ATAGG      39462   \n",
      "5507             91.27       3.345       0.00232      GATAG      39482   \n",
      "5508            110.77       2.938       0.01859      CTGAA      20349   \n",
      "5509             84.47       1.617       0.00232      GCTAT      87568   \n",
      "5510             88.33       2.099       0.00465      CAACC      33998   \n",
      "\n",
      "      end_idx  line_length  \n",
      "4000    21444           68  \n",
      "4001    88155           80  \n",
      "4002    93173           66  \n",
      "4003    93329           67  \n",
      "4004    93438           81  \n",
      "...       ...          ...  \n",
      "5506    39469           69  \n",
      "5507    39489           69  \n",
      "5508    20405           70  \n",
      "5509    87575           67  \n",
      "5510    34012           69  \n",
      "\n",
      "[1511 rows x 11 columns]\n",
      "processing 6-th chunk\n",
      "1357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 contig  position reference_kmer  read_index  \\\n",
      "5511  ENST00000351111.6      1069          GGCTA           4   \n",
      "5512  ENST00000351111.6       757          GGAAG           4   \n",
      "5513  ENST00000351111.6       606          CCCCT           4   \n",
      "5514  ENST00000351111.6       597          CCCAG           4   \n",
      "5515  ENST00000351111.6      1299          AATTA           4   \n",
      "...                 ...       ...            ...         ...   \n",
      "6863  ENST00000351111.6       431          TCTGC           4   \n",
      "6864  ENST00000351111.6      1130          CCTTG           4   \n",
      "6865  ENST00000351111.6       354          CGGAA           4   \n",
      "6866  ENST00000351111.6        14          GGCCG           4   \n",
      "6867  ENST00000351111.6       180          GCCAT           4   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "5511            112.34       4.623       0.01959      GGCTA      33046   \n",
      "5512            108.26       6.838       0.00432      GGAAG      51406   \n",
      "5513             64.71       1.567       0.00332      CCCCT      59317   \n",
      "5514             74.00       1.595       0.00365      CCCAG      59679   \n",
      "5515             95.92       3.227       0.00232      AATTA      23670   \n",
      "...                ...         ...           ...        ...        ...   \n",
      "6863             88.51       1.273       0.00266      TCTGC      68159   \n",
      "6864             77.70       1.280       0.00963      CCTTG      30435   \n",
      "6865            129.09       2.142       0.00531      CGGAA      71740   \n",
      "6866            104.48       2.716       0.00863      GGCCG      91982   \n",
      "6867             76.18       4.596       0.00498      GCCAT      80083   \n",
      "\n",
      "      end_idx  line_length  \n",
      "5511    33105           70  \n",
      "5512    51419           81  \n",
      "5513    59327           82  \n",
      "5514    59690           67  \n",
      "5515    23677           69  \n",
      "...       ...          ...  \n",
      "6863    68167           68  \n",
      "6864    30464           67  \n",
      "6865    71756           83  \n",
      "6866    92008           68  \n",
      "6867    80098           68  \n",
      "\n",
      "[1357 rows x 11 columns]\n",
      "processing 7-th chunk\n",
      "132\n",
      "                 contig  position reference_kmer  read_index  \\\n",
      "6868  ENST00000351111.6      1340          AGAAC           5   \n",
      "6869  ENST00000351111.6       409          TGGAG           5   \n",
      "6870  ENST00000351111.6      1093          TCACT           5   \n",
      "6871  ENST00000351111.6       785          CTCGT           5   \n",
      "6872  ENST00000351111.6       814          CGCAT           5   \n",
      "...                 ...       ...            ...         ...   \n",
      "6995  ENST00000351111.6      1087          CCTTG           5   \n",
      "6996  ENST00000351111.6       586          ACTCC           5   \n",
      "6997  ENST00000351111.6       183          ATCCA           5   \n",
      "6998  ENST00000351111.6       438          CCCCT           5   \n",
      "6999  ENST00000351111.6       204          TCTCC           5   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "6868            126.18       8.553       0.01328      AGAAC      14974   \n",
      "6869            120.02       3.583       0.01726      TGGAG      54106   \n",
      "6870             75.24       1.668       0.02025      TCACT      24555   \n",
      "6871             81.37       2.009       0.00697      CTCGT      38974   \n",
      "6872             90.23      10.140       0.00398      CGCAT      37607   \n",
      "...                ...         ...           ...        ...        ...   \n",
      "6995             76.00       1.524       0.00531      CCTTG      24790   \n",
      "6996             79.12       1.496       0.00398      ACTCC      47686   \n",
      "6997             70.77       1.102       0.00631      ATCCA      63485   \n",
      "6998             62.97       1.295       0.00432      CCCCT      53120   \n",
      "6999             74.42       0.852       0.00299      TCTCC      62751   \n",
      "\n",
      "      end_idx  line_length  \n",
      "6868    15014           95  \n",
      "6869    54158           69  \n",
      "6870    24616           82  \n",
      "6871    38995           82  \n",
      "6872    37619           68  \n",
      "...       ...          ...  \n",
      "6995    24806           82  \n",
      "6996    47698           68  \n",
      "6997    63504           82  \n",
      "6998    53133           68  \n",
      "6999    62760           68  \n",
      "\n",
      "[132 rows x 11 columns]\n",
      "processing 8-th chunk\n",
      "1115\n",
      "                 contig  position reference_kmer  read_index  \\\n",
      "7000  ENST00000351111.6       828          CTGCG           5   \n",
      "7001  ENST00000351111.6      1087          CCTTG           5   \n",
      "7002  ENST00000351111.6       397          TGAAG           5   \n",
      "7003  ENST00000351111.6      1357          CAAGC           5   \n",
      "7004  ENST00000351111.6       576          TTTAT           5   \n",
      "...                 ...       ...            ...         ...   \n",
      "8110  ENST00000351111.6      1279          TCACA           5   \n",
      "8111  ENST00000351111.6      1498          TTGGG           5   \n",
      "8112  ENST00000351111.6       310          TGGCT           5   \n",
      "8113  ENST00000351111.6       119          TGTGA           5   \n",
      "8114  ENST00000351111.6       363          AAGAT           5   \n",
      "\n",
      "      event_level_mean  event_stdv  event_length model_kmer  start_idx  \\\n",
      "7000            100.25       3.226       0.00332      CTGCG      37013   \n",
      "7001             77.49       1.435       0.00432      CCTTG      24820   \n",
      "7002            110.76       6.409       0.00432      TGAAG      54587   \n",
      "7003             93.98       5.217       0.00730      CAAGC      14175   \n",
      "7004             82.12       1.686       0.00432      TTTAT      48239   \n",
      "...                ...         ...           ...        ...        ...   \n",
      "8110             74.94       1.653       0.03619      TCACA      16991   \n",
      "8111             96.14       2.245       0.00365      TTGGG       9386   \n",
      "8112            110.66       6.619       0.02191      TGGCT      57814   \n",
      "8113             68.99       4.161       0.00398      TGTGA      65591   \n",
      "8114            123.54       6.601       0.00398      AAGAT      55679   \n",
      "\n",
      "      end_idx  line_length  \n",
      "7000    37023           96  \n",
      "7001    24833           69  \n",
      "7002    54600           69  \n",
      "7003    14197           81  \n",
      "7004    48252           68  \n",
      "...       ...          ...  \n",
      "8110    17100           69  \n",
      "8111     9397           67  \n",
      "8112    57880           69  \n",
      "8113    65603           81  \n",
      "8114    55691           69  \n",
      "\n",
      "[1115 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bec24affed98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meventalign_log_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eventalign.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_successful\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meventalign_log_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mparallel_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meventalign_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# parallel_preprocess_tx(eventalign_filepath,out_dir,n_processes,readcount_min,readcount_max,resume)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-471ada326ad5>\u001b[0m in \u001b[0;36mparallel_index\u001b[0;34m(eventalign_filepath, summary_filepath, chunk_size, out_dir, n_processes, resume)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mchunk_concat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'line_length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mtask_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_concat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mpos_start\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mchunk_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'read_index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'read_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/m6anet/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Queue {self!r} is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "misc.makedirs(out_dir) #todo: check every level.\n",
    "    \n",
    "# (1) For each read, combine multiple events aligned to the same positions, the results from nanopolish eventalign, into a single event per position.\n",
    "eventalign_log_filepath = os.path.join(out_dir,'eventalign.log')\n",
    "if not helper.is_successful(eventalign_log_filepath):\n",
    "    parallel_index(eventalign_filepath,summary_filepath,chunk_size,out_dir,n_processes,resume)\n",
    "    \n",
    "# parallel_preprocess_tx(eventalign_filepath,out_dir,n_processes,readcount_min,readcount_max,resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-locator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-m6anet] *",
   "language": "python",
   "name": "conda-env-.conda-m6anet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
